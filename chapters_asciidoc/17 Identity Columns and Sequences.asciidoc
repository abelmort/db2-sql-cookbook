[[identity.columns.chapter]]
== Identity Columns and Sequences

Imagine that one has an INVOICE table that records invoices generated. Also imagine that one wants every new invoice that goes into this table to get an invoice number value that is part of a unique and unbroken sequence of ascending values - assigned in the order that the invoices are generated. So if the highest invoice number is currently 12345, then the next invoice will get 12346, and then 12347, and so on. There are three ways to do this, up to a point:

* Use an identity column, which generates a unique value per row in a table.
* Use a sequence, which generates a unique value per one or more tables.
* Do it yourself, using an insert trigger to generate the unique values.

You may need to know what values were generated during each insert. There are several ways to do this:

* For all of the above techniques, embed the insert inside a select statement (see figure 795 and/or page 71). This is probably the best solution.
* For identity columns, use the IDENTITY_VAL_LOCAL function (see <<identity_val_local.function>>).
* For sequences, make a NEXTVAL or PREVVAL call (see <<nextval.and.prevval.usage.notes>>).

*Living With Gaps*

The only way that one can be absolutely certain not to have a gap in the sequence of values generated is to create your own using an insert trigger. However, this solution is probably the least efficient of those listed here, and it certainly has the least concurrency. There is almost never a valid business reason for requiring an unbroken sequence of values. So the best thing to do, if your users ask for such a feature, is to beat them up.

*Living With Sequence Errors*

For efficiency reasons, identity column and sequence values are usually handed out (to users doing inserts) in block of values, where the block size is defined using the CACHE option. If a user inserts a row, and then dithers for a bit before inserting another, it is possible that some other user (with a higher value) will insert first. In this case, the identity column or sequence value will be a good approximation of the insert sequence, but not right on. If the users need to know the precise order with which rows were inserted, then either set the cache size to one, which will cost, or include a current timestamp value.

=== Identity Columns

One can define a column in a Db2 table as an "identity column". This column, which must be numeric (note: fractional fields not allowed), will be incremented by a fixed constant each time a new row is inserted.

Below is an example of a typical invoice table that uses an identity column that starts at one, and then goes ever upwards:

.Identity column, sample table
[source,sql]
....
CREATE TABLE invoice_data
 ( invoice# INTEGER           NOT NULL
                    GENERATED ALWAYS AS IDENTITY
                   ( START WITH 1
                   , INCREMENT BY 1
                   , NO MAXVALUE
                   , NO CYCLE,
                   ORDER)
 , sale_date   DATE           NOT NULL
 , customer_id CHAR(20)       NOT NULL
 , product_id  INTEGER        NOT NULL
 , quantity    INTEGER        NOT NULL
 , price       DECIMAL(18, 2) NOT NULL
 , PRIMARY KEY (invoice#));
....

[[identity.rules.and.restrictions]]
=== Rules and Restrictions

Identity columns come in one of two general flavors:

* The value is always generated by Db2.
* The value is generated by Db2 only if the user does not provide a value (i.e. by default). This configuration is typically used when the input is coming from an external source (e.g. data propagation).

=== Rules

* There can only be one identity column per table.
* The field cannot be updated if it is defined "generated always".
* The column type must be numeric and must not allow fractional values. Any integer type is OK. Decimal is also fine, as long as the scale is zero. Floating point is a no-no.
* The identity column value is generated before any BEFORE triggers are applied. Use a trigger transition variable to see the value.
* A unique index is not required on the identity column, but it is a good idea. Certainly, if the value is being created by Db2, then a non-unique index is a fairly stupid idea.
* Unlike triggers, identity column logic is invoked and used during a LOAD. However, a load-replace will not reset the identity column value.
Use the RESTART command (see below) to do this. An identity column is not affected by a REORG.

=== Syntax Notes

*START WITH* defines the start value, which can be any valid integer value. If no start value is provided, then the default is the MINVALUE for ascending sequences, and the MAXVALUE for descending sequences. If this value is also not provided, then the default is 1.

*INCREMENT BY* defines the interval between consecutive values. This can be any valid integer value, though using zero is pretty silly. The default is 1.

*MINVALUE* defines (for ascending sequences) the value that the sequence will start at if no start value is provided. It is also the value that an ascending sequence will begin again at after it reaches the maximum and loops around. If no minimum value is provided, then after reaching the maximum the sequence will begin again at the start value. If that is also not defined, then the sequence will begin again at 1, which is the default start value. For descending sequences, it is the minimum value that will be used before the sequence loops around, and starts again at the maximum value.

*MAXVALUE* defines (for ascending sequences) the value that a sequence will stop at, and then go back to the minimum value. For descending sequences, it is the start value (if no start value is provided), and also the restart value - if the sequence reaches the minimum and loops around.

*CYCLE* defines whether the sequence should cycle about when it reaches the maximum value (for an ascending sequences), or whether it should stop. The default is no cycle.

*CACHE* defines whether or not to allocate sequences values in chunks, and thus to save on log writes. The default is no cache, which means that every row inserted causes a log write (to save the current value). If a cache value (from 2 to 20) is provided, then the new values are assigned to a common pool in blocks. Each insert user takes from the pool, and only when all of the values are used is a new block (of values) allocated and a log write done. If the table is deactivated, either normally or otherwise, then the values in the current block are discarded, resulting in gaps in the sequence. Gaps in the sequence of values also occur when an insert is subsequently rolled back, so they cannot be avoided. But don't use the cache if you want to try and avoid them.

*ORDER* defines whether all new rows inserted are assigned a sequence number in the order that they were inserted. The default is no, which means that occasionally a row that is inserted after another may get a slightly lower sequence number. This is the default. 

=== Identity Column Examples

The following example uses all of the defaults to start an identity column at one, and then to go up in increments of one. The inserts will eventually die when they reach the maximum allowed value for the field type (i.e. for small integer = 32K). 

.Identity column, ascending sequence
[source,sql]
....
CREATE TABLE test_data
( key# SMALLINT NOT NULL
                GENERATED ALWAYS AS IDENTITY
, dat1 SMALLINT NOT NULL
, ts1 TIMESTAMP NOT NULL
, PRIMARY KEY(key#));

--	KEY# FIELD - VALUES ASSIGNED
--  1 2 3 4 5 6 7 8 9 10 11 etc.
....

The next example defines an identity column that goes down in increments of -3:

.Identity column, descending sequence
[source,sql]
....
CREATE TABLE test_data
( key# SMALLINT NOT NULL
                GENERATED ALWAYS AS IDENTITY
                ( START WITH 6
                , INCREMENT BY -3
                , NO CYCLE
                , NO CACHE
                , ORDER)
, dat1 SMALLINT NOT NULL
, ts1 TIMESTAMP NOT NULL
, PRIMARY KEY(key#));

-- KEY# FIELD - VALUES ASSIGNED
--  6 3 0 -3 -6 -9 -12 -15 etc.
....

The next example, which is amazingly stupid, goes nowhere fast. A primary key cannot be defined on this table:

.Identity column, dumb sequence
[source,sql]
....
CREATE TABLE test_data
(key# SMALLINT NOT NULL
               GENERATED ALWAYS AS IDENTITY
               ( START WITH 123
               , MAXVALUE 124
               , INCREMENT BY 0
               , NO CYCLE
               , NO ORDER)
, dat1 SMALLINT NOT NULL
, ts1 TIMESTAMP NOT NULL);

-- KEY# VALUES ASSIGNED
-- 123 123 123 123 123 123 etc.
....

The next example uses every odd number up to the maximum (i.e. 6), then loops back to the minimum value, and goes through the even numbers, ad-infinitum:

.Identity column, odd values, then even, then stuck
[source,sql]
....
CREATE TABLE test_data
( key# SMALLINT NOT NULL
                GENERATED ALWAYS AS IDENTITY
                ( START WITH 1
                , INCREMENT BY 2
                , MAXVALUE 6
                , MINVALUE 2
                , CYCLE
                , NO CACHE
                , ORDER)
, dat1 SMALLINT NOT NULL
, ts1 TIMESTAMP NOT NULL);

-- KEY# VALUES ASSIGNED0
-- 1 3 5 2 4 6 2 4 6 2 4 6 etc.
....

=== Usage Examples

Below is the DDL for a simplified invoice table where the primary key is an identity column. Observe that the invoice# is always generated by Db2:

.Identity column, definition
[source,sql]
....
CREATE TABLE invoice_data
( invoice# INTEGER     NOT NULL
                   GENERATED ALWAYS AS IDENTITY
                   ( START WITH 100
                   , INCREMENT BY 1
                   , NO CYCLE
                   , ORDER)
, sale_date DATE       NOT NULL
, customer_id CHAR(20) NOT NULL
, product_id INTEGER   NOT NULL
, quantity INTEGER     NOT NULL
, price DECIMAL(18, 2) NOT NULL
, PRIMARY KEY (invoice#));
....

One cannot provide a value for the invoice# when inserting into the above table. Therefore, one must either use a default placeholder, or leave the column out of the insert. An example of both techniques is given below. The second insert also selects the generated values: 

.Invoice table, sample inserts
[source,sql]
....
INSERT INTO invoice_data
VALUES (DEFAULT, '2001-11-22', 'ABC', 123, 100, 10);

SELECT invoice# 
FROM FINAL TABLE
    (INSERT INTO invoice_data
    (sale_date, customer_id, product_id, quantity,price)
    VALUES ('2002-11-22', 'DEF', 123, 100, 10)
         , ('2003-11-22', 'GHI', 123, 100, 10));
....

_ANSWER_

[cols="",options="header",]
|===
|INVOICE#
|101
|102
|===

Below is the state of the table after the above two inserts:
.Invoice table, after inserts
|===
|INVOICE#|SALE_DATE |CUSTOMER_ID|PRODUCT_ID|QUANTITY|PRICE
|100     |2001-11-22|ABC        |123       |100     |10.00
|101     |2002-11-22|DEF        |123       |100     |10.00
|102     |2003-11-22|GHI        |123       |100     |10.00
|===

=== Altering Identity Column Options

Imagine that the application is happily collecting invoices in the above table, but your silly boss is unhappy because not enough invoices, as measured by the ever-ascending invoice# value, are being generated per unit of time. We can improve things without actually fixing any difficult business problems by simply altering the invoice# current value and the increment using the ALTER TABLE ... RESTART command: 

.Invoice table, restart identity column value
[source,sql]
....
ALTER TABLE invoice_data
    ALTER COLUMN invoice#
        RESTART WITH 1000
        SET INCREMENT BY 2;
....

Now imagine that we insert two more rows thus:

.Invoice table, more sample inserts
[source,sql]
....
INSERT INTO invoice_data
    VALUES (DEFAULT, '2004-11-24', 'XXX', 123, 100, 10)
         , (DEFAULT, '2004-11-25', 'YYY', 123, 100, 10);
....

Our mindless management will now see this data:

.Invoice table, after second inserts
|===
|INVOICE#|SALE_DATE |CUSTOMER_ID|PRODUCT_ID|QUANTITY|PRICE
|100     |2001-11-22|ABC        |123       |100     |10.00
|101     |2002-11-22|DEF        |123       |100     |10.00
|102     |2003-11-22|GHI        |123       |100     |10.00
|1000    |2004-11-24|XXX        |123       |100     |10.00
|1002    |2004-11-25|YYY        |123       |100     |10.00
|===

Restarting the identity column start number to a lower number, or to a higher number if the increment is a negative value, can result in the column getting duplicate values. This can also occur if the increment value is changed from positive to negative, or vice-versa. If no value is provided for the restart option, the sequence restarts at the previously defined start value.

=== Gaps in Identity Column Values

If an identity column is generated always, and no cache is used, and the increment value is 1, then there will usually be no gaps in the sequence of assigned values. But gaps can occur if an insert is subsequently rolled out instead of committed. In the following example, there will be no row in the table with customer number "1" after the rollback: 

.Gaps in Values, example
[source,sql]
....
CREATE TABLE customers
( cust# INTEGER NOT NULL
                GENERATED ALWAYS AS IDENTITY (NO CACHE)
, cname CHAR(10) NOT NULL
, ctype CHAR(03) NOT NULL
, PRIMARY KEY (cust#));

COMMIT;

SELECT cust#
FROM FINAL TABLE
    (INSERT INTO customers
     VALUES (DEFAULT, 'FRED', 'XXX'));

ROLLBACK;
....

_ANSWER_

[cols="",options="header",]
|===
|CUST#
|1
|===

.Gaps in Values, example
[source,sql]
....
SELECT cust#
FROM FINAL TABLE
    (INSERT INTO customers
     VALUES (DEFAULT, 'FRED', 'XXX'));

COMMIT;
....

_ANSWER_

[cols="",options="header",]
|===
|CUST#
|2
|===

[[find.gaps.in.values]]
=== Find Gaps in Values

The following query can be used to list the missing values in a table. It starts by getting the minimum and maximum values. It next generates every value in between. Finally, it checks the generated values against the source tables. Non-matches are selected.

.Find gaps in values
[source,sql]
....
WITH generate_values (min_val, max_val, num_val, cur_val) AS
(SELECT MIN(dat1)
       , MAX(dat1)
       , COUNT(*)
       , MIN(dat1)
 FROM test_data td1
   UNION ALL
 SELECT min_val
      , max_val
      , num_val
      , cur_val + 1
 FROM generate_values gv1
 WHERE cur_val < max_val
)
SELECT *
FROM generate_values gv2
WHERE NOT EXISTS
    (SELECT *
     FROM test_data td2
     WHERE td2.dat1 = cur_val)
ORDER BY cur_val;
....

_INPUT_

[cols="",options="header",]
|===
|DAT1
|1
|2
|3
|4
|6
|7
|9
|10
|===

_ANSWER_
|===
|MIN_VAL|MAX_VAL|NUM_VAL|CUR_VAL
|1      |10     |8      |5
|1      |10     |8      |8
|===

The above query may be inefficient if there is no suitable index on the DAT1 column. The next query gets around this problem by using an EXCEPT instead of a sub-query:

.Find gaps in values
[source,sql]
....
WITH generate_values (min_val, max_val, num_val, cur_val) AS
(SELECT MIN(dat1)
      , MAX(dat1)
      , COUNT(*)
      , MIN(dat1)
 FROM test_data td1
   UNION ALL
 SELECT min_val
      , max_val
      , num_val
      , cur_val + 1
 FROM generate_values gv1
 WHERE cur_val < max_val)
SELECT cur_val
FROM generate_values gv2
  EXCEPT ALL
SELECT dat1
FROM test_data td2
ORDER BY 1;
....

_INPUT_

[cols="",options="header",]
|===
|DAT1
|1
|2
|3
|4
|6
|7
|9
|10
|===

_ANSWER_

[cols="",options="header",]
|===
|CUR_VAL
|5
|8
|===

The next query uses a totally different methodology. It assigns a rank to every value, and then looks for places where the rank and value get out of step:

.Find gaps in values
[source,sql]
....
WITH assign_ranks AS
(SELECT dat1
      , DENSE_RANK() OVER(ORDER BY dat1) AS rank#
 FROM test_data)
, locate_gaps AS
(SELECT dat1 - rank# AS diff
      , min(dat1) AS min_val
      , max(dat1) AS max_val
      , ROW_NUMBER() OVER(ORDER BY dat1 - rank#) AS gap#
 FROM assign_ranks ar1
 GROUP BY dat1 - rank#)
SELECT lg1.gap# AS gap#
     , lg1.max_val AS prev_val
     , lg2.min_val AS next_val
     , lg2.min_val - lg1.max_val AS diff
FROM locate_gaps lg1
   , locate_gaps lg2
WHERE lg2.gap# = lg1.gap# + 1
ORDER BY lg1.gap#;
....

_ANSWER_
|===
|GAP#|PREV_VAL|NEXT_VAL|DIFF
|1   |4       |6       |2
|2   |7       |9       |2
|===

==== IDENTITY_VAL_LOCAL Function

There are two ways to find out what values were generated when one inserted a row into a table with an identity column:

* Embed the insert within a select statement (see figure 795).
* Call the IDENTITY_VAL_LOCAL function.

Certain rules apply to IDENTITY_VAL_LOCAL function usage:

* The value returned from is a decimal (31.0) field.
* The function returns null if the user has not done a single-row insert in the current unit of work. Therefore, the function has to be invoked before one does a commit. Having said this, in some versions of Db2 it seems to work fine after a commit.
* If the user inserts multiple rows into table(s) having identity columns in the same unit of work, the result will be the value obtained from the last single-row insert. The result will be null if there was none.
* Multiple-row inserts are ignored by the function. So if the user first inserts one row, and then separately inserts two rows (in a single SQL statement), the function will return the identity column value generated during the first insert.
* The function cannot be called in a trigger or SQL function. To get the current identity column value in an insert trigger, use the trigger transition variable for the column. The value, and thus the transition variable, is defined before the trigger is begun.
* If invoked inside an insert statement (i.e. as an input value), the value will be taken from the most recent (previous) single-row insert done in the same unit of work. The result will be null if there was none.
* The value returned by the function is unpredictable if the prior single-row insert failed. It may be the value from the insert before, or it may be the value given to the failed insert.
* The function is non-deterministic, which means that the result is determined at fetch time (i.e. not at open) when used in a cursor. So if one fetches a row from a cursor, and then does an insert, the next fetch may get a different value from the prior.
* The value returned by the function may not equal the value in the table - if either a trigger or an update has changed the field since the value was generated. This can only occur if the identity column is defined as being "generated by default". An identity column that is "generated always" cannot be updated.
* When multiple users are inserting into the same table concurrently, each will see their own most recent identity column value. They cannot see each other's.

If the above sounds unduly complex, it is because it is. It is often much easier to simply get the values by embedding the insert inside a select:

.Selecting identity column values inserted
[source,sql]
....
SELECT MIN(cust#) AS minc
     , MAX(cust#) AS maxc
     , COUNT(*) AS rows
FROM FINAL TABLE
    (INSERT INTO customers
     VALUES (DEFAULT, 'FRED', 'xxx')
          , (DEFAULT, 'DAVE', 'yyy')
          , (DEFAULT, 'JOHN', 'zzz'));
....

_ANSWER_
|===
|MINC|MAXC|ROWS
|3   |5   |3
|===

Below are two examples of the function in use. Observe that the second invocation (done after the commit) returned a value, even though it is supposed to return null:

.IDENTITY_VAL_LOCAL function examples
[source,sql]
....
CREATE TABLE invoice_table
( invoice# INTEGER NOT NULL
                   GENERATED ALWAYS AS IDENTITY
, sale_date DATE NOT NULL
, customer_id CHAR(20) NOT NULL
, product_id INTEGER NOT NULL
, quantity INTEGER NOT NULL
, price DECIMAL(18,2) NOT NULL
, PRIMARY KEY (invoice#));

COMMIT;

INSERT INTO invoice_table
VALUES (DEFAULT, '2000-11-22', 'ABC', 123, 100, 10);

WITH temp (id) AS
  (VALUES (IDENTITY_VAL_LOCAL()))
SELECT *
FROM temp;    --> ANSWER: ID = 1

COMMIT;

WITH temp (id) AS
  (VALUES (IDENTITY_VAL_LOCAL()))
SELECT *
FROM temp;    --> ANSWER: ID = 1
....

In the next example, two separate inserts are done on the table defined above. The first inserts a single row, and so sets the function value to "2". The second is a multi-row insert, and so is ignored by the function:

.IDENTITY_VAL_LOCAL function examples
[source,sql]
....
INSERT INTO invoice_table
  VALUES (DEFAULT, '2000-11-23', 'ABC', 123, 100, 10);
INSERT INTO invoice_table
  VALUES (DEFAULT, '2000-11-24', 'ABC', 123, 100, 10)
       , (DEFAULT, '2000-11-25', 'ABC', 123, 100, 10);

SELECT invoice# AS inv#
     , sale_date
     , IDENTITY_VAL_LOCAL() AS id
FROM invoice_table
ORDER BY 1;

COMMIT;
....

_ANSWER_
|===
|INV#|SALE_DATE |ID
|1   |11/22/2000|2
|2   |11/23/2000|2
|3   |11/24/2000|2
|4   |11/25/2000|2
|===

One can also use the function to get the most recently inserted single row by the current user:

.IDENTITY_VAL_LOCAL usage in predicate
[source,sql]
....
SELECT invoice# AS inv#
     , sale_date
     , IDENTITY_VAL_LOCAL() AS id
FROM invoice_table
WHERE id = IDENTITY_VAL_LOCAL();
....

_ANSWER_
|===
|INV#|SALE_DATE |ID
|2   |11/23/2000|2
|===

=== Sequences

A sequence is almost the same as an identity column, except that it is an object that exists outside of any particular table. 

.Create sequence
[source,sql]
....
CREATE SEQUENCE fred
  AS DECIMAL(31)
  START WITH 100
  INCREMENT BY 2
  NO MINVALUE
  NO MAXVALUE
  NO CYCLE
  CACHE 20
  ORDER;

-- SEQ# VALUES ASSIGNED
-- 100 102 104 106 etc.
....

The options and defaults for a sequence are exactly the same as those for an identity column (see <<identity.rules.and.restrictions>>). Likewise, one can alter a sequence in much the same way as one would alter the status of an identity column:

.Alter sequence attributes
[source,sql]
....
ALTER SEQUENCE fred
  RESTART WITH -55
  INCREMENT BY -5
  MINVALUE -1000
  MAXVALUE +1000
  NO CACHE
  NO ORDER
  CYCLE;

-- SEQ# VALUES ASSIGNED
-- -55 -60 -65 -70 etc.
....

The only sequence attribute that one cannot change with the ALTER command is the field type that is used to hold the current value.

==== Constant Sequence

If the increment is zero, the sequence will stay whatever value one started it with until it is altered. This can be useful if wants to have a constant that can be globally referenced:

.Sequence that doesn't change
[source,sql]
....
CREATE SEQUENCE biggest_sale_to_date
  AS INTEGER
  START WITH 345678
  INCREMENT BY 0;

-- SEQ# VALUES ASSIGNED
-- 345678, 345678, etc.
....

==== Getting the Sequence Value

There is no concept of a current sequence value. Instead one can either retrieve the next or the previous value (if there is one). And any reference to the next value will invariably cause the sequence to be incremented. The following example illustrates this:

.Selecting the NEXTVAL
[source,sql]
....
CREATE SEQUENCE fred;

COMMIT;

WITH temp1 (n1) AS
 (VALUES 1
    UNION ALL
  SELECT n1 + 1
  FROM temp1
  WHERE n1 < 5
 )
 SELECT NEXTVAL FOR fred AS seq#
 FROM temp1;
....

_ANSWER_

[cols="",options="header",]
|===
|SEQ#
|1
|2
|3
|4
|5
|===

[[nextval.and.prevval.usage.notes]]
==== NEXTVAL and PREVVAL - Usage Notes

* One retrieves the next or previous value using a "NEXTVAL FOR sequence-name", or a "PREVVAL for sequence-name" call.
* A NEXTVAL call generates and returns the next value in the sequence. Thus, each call will consume the returned value. This remains true even if the statement that did the retrieval subsequently fails or is rolled back.
* A PREVVAL call returns the most recently generated value for the specified sequence for the current connection. Unlike when getting the next value, getting the prior value does not alter the state of the sequence, so multiple calls can retrieve the same value.
* If no NEXTVAL reference (to the target sequence) has been made for the current connection, any attempt to get the PREVVAL will result in a SQL error.

==== NEXTVAL and PREVVAL - Usable Statements

* SELECT INTO statement (within the select part), as long as there is no DISTINCT, GROUP BY, UNION, EXECPT, or INTERSECT.
* INSERT statement - with restrictions.
* UPDATE statement - with restrictions.
* SET host variable statement.

==== NEXTVAL - Usable Statements

* A trigger.

==== NEXTVAL and PREVVAL - Not Allowed In

* DELETE statement.
* Join condition of a full outer join.
* Anywhere in a CREATE TABLE or CREATE VIEW statement.

==== NEXTVAL - Not Allowed In

* CASE expression
* Join condition of a join.
* Parameter list of an aggregate function.
* SELECT statement where there is an outer select that contains a DISTINCT, GROUP BY, UNION, EXCEPT, or INTERSECT.
* Most sub-queries.

==== PREVVAL - Not Allowed In

* A trigger.

There are many more usage restrictions, but you presumably get the picture. See the Db2 SQL Reference for the complete list. 

=== Usage Examples

Below a sequence is defined, then various next and previous values are retrieved:

.NEXTVAL and PREVVAL expressions
[source,sql]
....
CREATE SEQUENCE fred;

COMMIT;

WITH temp1 (prv) AS
  (VALUES (PREVVAL FOR fred))
SELECT *
FROM temp1; -->  PRV : <error>

WITH temp1 (nxt) AS
  (VALUES (NEXTVAL FOR fred))
SELECT *
FROM temp1; --> NXT: 1

WITH temp1 (prv) AS
  (VALUES (PREVVAL FOR fred))
SELECT *
FROM temp1; --> PRV: 1

WITH temp1 (n1) AS 
  (VALUES 1 
     UNION ALL
   SELECT n1 + 1
   FROM temp1
   WHERE n1 < 5
  )
SELECT NEXTVAL FOR fred AS nxt
     , PREVVAL FOR fred AS prv
FROM temp1;
....
|===
|NXT|PRV
|2  |1
|3  |1
|4  |1
|5  |1
|6  |1
|===

One does not actually have to fetch a NEXTVAL result in order to increment the underlying sequence. In the next example, some of the rows processed are thrown away halfway thru the query, but their usage still affects the answer (of the subsequent query):

.NEXTVAL values used but not retrieved
[source,sql]
....
CREATE SEQUENCE fred; 

COMMIT;

WITH temp1 AS
  (SELECT id
        , NEXTVAL FOR fred AS nxt
   FROM staff
   WHERE id < 100
  )
SELECT *
FROM temp1
WHERE id = 50 + (nxt * 0);
....
|===
|ID|NXT
|50|5
|===

[source,sql]
....
WITH temp1 (nxt, prv) AS
  (VALUES (NEXTVAL FOR fred
         , PREVVAL FOR fred))
SELECT *
FROM temp1;
....
|===
|NXT|PRV
|10 |9
|===

NOTE: The somewhat funky predicate at the end of the first query above prevents Db2 from stopping the nested-table-expression when it gets to "id = 50". If this were to occur, the last query above would get a next value of 6, and a previous value of 5.

=== Multi-table Usage

Imagine that one wanted to maintain a unique sequence of values over multiple tables. One can do this by creating a before insert trigger on each table that replaces whatever value the user provides with the current one from a common sequence. Below is an example:

.Create tables that use a common sequence
[source,sql]
....
CREATE SEQUENCE cust#
  START WITH 1
  INCREMENT BY 1
  NO MAXVALUE
  NO CYCLE
  ORDER;

CREATE TABLE us_customer
( cust# INTEGER  NOT NULL
, cname CHAR(10) NOT NULL
, frst_sale DATE NOT NULL
, #sales INTEGER NOT NULL
, PRIMARY KEY (cust#));

CREATE TRIGGER us_cust_ins
  NO CASCADE BEFORE INSERT ON us_customer
  REFERENCING NEW AS nnn
  FOR EACH ROW MODE Db2SQL
  SET nnn.cust# = NEXTVAL FOR cust#;

CREATE TABLE intl_customer
( cust# INTEGER  NOT NULL
, cname CHAR(10) NOT NULL
, frst_sale DATE NOT NULL
, #sales INTEGER NOT NULL
, PRIMARY KEY (cust#));

CREATE TRIGGER intl_cust_ins
  NO CASCADE BEFORE INSERT ON intl_customer
  REFERENCING NEW AS nnn
  FOR EACH ROW MODE Db2SQL
  SET nnn.cust# = NEXTVAL FOR cust#;
....

If we now insert some rows into the above tables, we shall find that customer numbers are assigned in the correct order, thus:

.Insert into tables with common sequence
[source,sql]
....
SELECT cust#
     , cname
FROM FINAL TABLE
(INSERT INTO us_customer (cname, frst_sale, #sales)
 VALUES ('FRED', '2002-10-22', 1)
      , ('JOHN', '2002-10-23', 1));

SELECT cust#
     , cname
FROM FINAL TABLE
(INSERT INTO intl_customer (cname, frst_sale, #sales)
 VALUES ('SUE', '2002-11-12', 2)
      , ('DEB', '2002-11-13', 2));
....

_ANSWERS_
|===
|CUST#|CNAME
|1    |FRED
|2    |JOHN
|===

|===
|CUST#|CNAME 
|3    |SUE
|4    |DEB
|===

One of the advantages of a standalone sequence over a functionally similar identity column is that one can use a PREVVAL expression to get the most recent value assigned (to the user), even if the previous usage was during a multi-row insert. Thus, after doing the above inserts, we can run the following query:

.Get previous value - select
[source,sql]
....
WITH temp (prev) AS
  (VALUES (PREVVAL FOR cust#))
SELECT *
FROM temp;
....

_ANSWER_

[cols="",options="header",]
|===
|PREV
|4
|===

The following does the same as the above, but puts the result in a host variable:

.Get previous value - into host-variable
[source,sql]
....
VALUES PREVVAL FOR CUST# INTO :host-var
....

As with identity columns, the above result will not equal what is actually in the table(s) – if the most recent insert was subsequently rolled back.

=== Counting Deletes

In the next example, two sequences are created: One records the number of rows deleted from a table, while the other records the number of delete statements run against the same:

.Count deletes done to table
[source,sql]
....
CREATE SEQUENCE delete_rows
  START WITH 1
  INCREMENT BY 1
  NO MAXVALUE
  NO CYCLE
  ORDER;

CREATE SEQUENCE delete_stmts
  START WITH 1
  INCREMENT BY 1
  NO MAXVALUE
  NO CYCLE
  ORDER;

CREATE TABLE customer
( cust# INTEGER  NOT NULL
, cname CHAR(10) NOT NULL
, frst_sale DATE NOT NULL
, #sales INTEGER NOT NULL
, PRIMARY KEY (cust#));

CREATE TRIGGER cust_del_rows
  AFTER DELETE ON customer
  FOR EACH ROW MODE Db2SQL
  WITH temp1 (n1) AS (VALUES(1))
  SELECT NEXTVAL FOR delete_rows
  FROM temp1;

CREATE TRIGGER cust_del_stmts
  AFTER DELETE ON customer
  FOR EACH STATEMENT MODE Db2SQL
  WITH temp1 (n1) AS (VALUES(1))
  SELECT NEXTVAL FOR delete_stmts
  FROM temp1;
....

Be aware that the second trigger will be run, and thus will update the sequence, regardless of whether a row was found to delete or not.

=== Identity Columns vs. Sequences - a Comparison

First to compare the two types of sequences:

* Only one identity column is allowed per table, whereas a single table can have multiple sequences and/or multiple references to the same sequence.
* Identity column sequences cannot span multiple tables. Sequences can. 
* Sequences require triggers to automatically maintain column values (e.g. during inserts) in tables. Identity columns do not.
* Sequences can be incremented during inserts, updates, deletes (via triggers), or selects, whereas identity columns only get incremented during inserts.
* Sequences can be incremented (via triggers) once per row, or once per statement. Identity columns are always updated per row inserted.
* Sequences can be dropped and created independent of any tables that they might be used to maintain values in. Identity columns are part of the table definition.
* Identity columns are supported by the load utility. Trigger induced sequences are not.

For both types of sequence, one can get the current value by embedding the DML statement inside a select (e.g. see figure 795). Alternatively, one can use the relevant expression to get the current status. These differ as follows:

* The *IDENTITY_VAL_LOCAL* function returns null if no inserts to tables with identity columns have been done by the current user. In an equivalent situation, the PREVVAL expression gets a nasty SQL error.
* The *IDENTITY_VAL_LOCAL* function ignores multi-row inserts (without telling you). In a similar situation, the PREVVAL expression returns the last value generated.
* One cannot tell to which table an *IDENTITY_VAL_LOCAL* function result refers to. This can be a problem in one insert invokes another insert (via a trigger), which puts are row in another table with its own identity column. By contrast, in the PREVVAL function one explicitly identifies the sequence to be read.
* There is no equivalent of the NEXTVAL expression for identity columns.

=== Roll Your Own

If one really, really, needs to have a sequence of values with no gaps, then one can do it using an insert trigger, but there are costs, in processing time, concurrency, and functionality. To illustrate, consider the following table:

.Sample table, roll your own sequence
[source,sql]
....
CREATE TABLE sales_invoice
( invoice#    INTEGER        NOT NULL
, sale_date   DATE           NOT NULL
, customer_id CHAR(20)       NOT NULL
, product_id  INTEGER        NOT NULL
, quantity    INTEGER        NOT NULL
, price       DECIMAL(18, 2) NOT NULL
, PRIMARY KEY (invoice#));
....

The following trigger will be invoked before each row is inserted into the above table. It sets the new invoice# value to be the current highest invoice# value in the table, plus one:

.Sample trigger, roll your own sequence
[source,sql]
....
CREATE TRIGGER sales_insert
  NO CASCADE BEFORE
  INSERT ON sales_invoice
  REFERENCING NEW AS nnn
  FOR EACH ROW
  MODE Db2SQL
  SET nnn.invoice# =
    (SELECT COALESCE(MAX(invoice#),0) + 1
     FROM sales_invoice);
....

The good news about the above setup is that it will never result in gaps in the sequence of values. In particular, if a newly inserted row is rolled back after the insert is done, the next insert will simply use the same invoice# value. But there is also bad news: 
* Only one user can insert at a time, because the select (in the trigger) needs to see the highest invoice# in the table in order to complete.
* Multiple rows cannot be inserted in a single SQL statement (i.e. a mass insert). The trigger is invoked before the rows are actually inserted, one row at a time, for all rows. Each row would see the same, already existing, high invoice#, so the whole insert would die due to a duplicate row violation.

There may be a tiny, tiny chance that if two users were to begin an insert at exactly the same time that they would both see the same high invoice# (in the before trigger), and so the last one to complete (i.e. to add a pointer to the unique invoice# index) would get a duplicate-row violation.

Below are some inserts to the above table. Ignore the values provided in the first field – they are replaced in the trigger. And observe that the third insert is rolled out:

.Sample inserts, roll your own sequence
[source,sql]
....
INSERT INTO sales_invoice VALUES (0, '2001-06-22' ,'ABC', 123, 10, 1);
INSERT INTO sales_invoice VALUES (0, '2001-06-23' ,'DEF', 453, 10, 1);
COMMIT;
INSERT INTO sales_invoice VALUES (0, '2001-06-24' ,'XXX', 888, 10, 1);
ROLLBACK;
INSERT INTO sales_invoice VALUES (0, '2001-06-25' ,'YYY', 999, 10, 1);
COMMIT;
....

_ANSWER_
|===
|INVOICE#|SALE_DATE |CUSTOMER_ID|PRODUCT_ID|QUANTITY|PRICE
|1       |06/22/2001|ABC        |123       |10      |1.00  
|2       |06/23/2001|DEF        |453       |10      |1.00
|3       |06/25/2001|YYY        |999       |10      |1.00
|===

=== Support Multi-row Inserts

The next design is more powerful in that it supports multi-row inserts, and also more than one table if desired. It requires that there be a central location that holds the current high-value. In the example below, this value will be in a row in a special control table. Every insert into the related data table will, via triggers, first update, and then query, the row in the control table.

==== Control Table

The following table has one row per sequence of values being maintained:

.Control Table, DDL
[source,sql]
....
CREATE TABLE control_table
( table_name CHAR(18) NOT NULL
, table_nmbr INTEGER  NOT NULL
, PRIMARY KEY (table_name));
....

Now to populate the table with some initial sequence# values:

.Control Table, sample inserts
[source,sql]
....
INSERT INTO control_table VALUES ('invoice_table', 0);
INSERT INTO control_table VALUES ('2nd_data_tble', 0);
INSERT INTO control_table VALUES ('3rd_data_tble', 0);
....

==== Data Table

Our sample data table has two fields of interest:

* The *UNQVAL* column will be populated, using a trigger, with a GENERATE_UNIQUE function output value. This is done before the row is actually inserted. Once the insert has completed, we will no longer care about or refer to the contents of this field.
* The *INVOICE#* column will be populated, using triggers, during the insert process with a unique ascending value. However, for part of the time during the insert the field will have a null value, which is why it is defined as being both non-unique and allowing nulls.

.Sample Data Table, DDL
[source,sql]
....
CREATE TABLE invoice_table 
( unqval      CHAR(13) FOR BIT DATA NOT NULL
, invoice#    INTEGER               NOT NULL
, sale_date   DATE                  NOT NULL
, customer_id CHAR(20)              NOT NULL
, product_id  INTEGER               NOT NULL
, quantity    INTEGER               NOT NULL
, price       DECIMAL(18, 2)        NOT NULL
, PRIMARY KEY(unqval));
....

Two insert triggers are required: The first acts before the insert is done, giving each new row a unique UNQVAL value: 

.Before trigger
[source,sql]
....
CREATE TRIGGER invoice1
  NO CASCADE BEFORE INSERT ON invoice_table
  REFERENCING NEW AS nnn
  FOR EACH ROW MODE Db2SQL
  SET nnn.unqval   = GENERATE_UNIQUE()
    , nnn.invoice# = NULL;
....

The second trigger acts after the row is inserted. It first increments the control table by one, then updates invoice# in the current row with the same value. The UNQVAL field is used to locate the row to be changed in the second update:

.After trigger
[source,sql]
....
CREATE TRIGGER invoice2
  AFTER INSERT ON invoice_table
  REFERENCING NEW AS nnn
  FOR EACH ROW MODE Db2SQL
  BEGIN ATOMIC
    UPDATE control_table
      SET table_nmbr = table_nmbr + 1
      WHERE table_name = 'invoice_table';
    UPDATE invoice_table
      SET invoice# =
               (SELECT table_nmbr
                FROM control_table
                WHERE table_name = 'invoice_table')
    WHERE unqval = nnn.unqval
    AND invoice# IS NULL;
  END
....

NOTE: The above two actions must be in a single trigger. If they are in two triggers, mass inserts will not work correctly because the first trigger (i.e. update) would be run (for all rows), followed by the second trigger (for all rows). In the end, every row inserted by the mass-insert would end up with the same invoice# value.

A final update trigger is required to prevent updates to the invoice# column:

.Update trigger
[source,sql]
....
CREATE TRIGGER invoice3
  NO CASCADE BEFORE UPDATE OF invoice# ON invoice_table
  REFERENCING OLD AS ooo
  NEW AS nnn
  FOR EACH ROW MODE Db2SQL
  WHEN (ooo.invoice# <> nnn.invoice#)
    SIGNAL SQLSTATE '71001' ('no updates allowed - you twit');
....

=== Design Comments

Though the above design works, it has certain practical deficiencies:

* The single row in the control table is a point of contention, because only one user can update it at a time. One must therefore commit often (perhaps more often than one would like to) in order to free up the locks on this row. Therefore, by implication, this design puts one is at the mercy of programmers.
* The two extra updates add a considerable overhead to the cost of the insert.
* The invoice number values generated by AFTER trigger cannot be obtained by selecting from an insert statement (see <<insert.examples>>). In fact, selecting from the FINAL TABLE will result in a SQL error. One has to instead select from the NEW TABLE, which returns the new rows before the AFTER trigger was applied.

As with ordinary sequences, this design enables one to have multiple tables referring to a single row in the control table, and thus using a common sequence.


